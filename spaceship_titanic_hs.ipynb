{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3qLk5IxvTRGcLoWrSrY8d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFxHazgN1NoC","executionInfo":{"status":"ok","timestamp":1700739718600,"user_tz":-540,"elapsed":2010,"user":{"displayName":"서형석","userId":"16583095969502807505"}},"outputId":"d5d988ce-00fd-4389-cee2-54ac9aeb03aa"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!git clone https://hyeongseok21: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@github.com/hyeongseok21/kaggle.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkkZ7cuW5if8","executionInfo":{"status":"ok","timestamp":1700739860069,"user_tz":-540,"elapsed":1914,"user":{"displayName":"서형석","userId":"16583095969502807505"}},"outputId":"4ae155e3-2f38-45fe-b9b5-b55b1c4d57be"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'kaggle'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (6/6), done.\n"]}]},{"cell_type":"code","source":["!git config --global user.email 'wimpr0730@gmail.com'\n","!git config --global user.name 'hyeongseok21'"],"metadata":{"id":"pSXhcuoo-qZp","executionInfo":{"status":"ok","timestamp":1700739869303,"user_tz":-540,"elapsed":326,"user":{"displayName":"서형석","userId":"16583095969502807505"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["!git remote add origin https://hyeongseok21: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@github.com/hyeongseok21/kaggle.git"],"metadata":{"id":"_54JTY8R8js3","executionInfo":{"status":"ok","timestamp":1700740286476,"user_tz":-540,"elapsed":294,"user":{"displayName":"서형석","userId":"16583095969502807505"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sgs55KWkBU-6","executionInfo":{"status":"ok","timestamp":1700740330253,"user_tz":-540,"elapsed":547,"user":{"displayName":"서형석","userId":"16583095969502807505"}},"outputId":"51a951fe-3cc3-4adc-e7d6-80acd9c163d4"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Invalid username or password.\n","fatal: Authentication failed for 'https://github.com/hyeongseok21/kaggle.git/'\n"]}]},{"cell_type":"markdown","source":["# 1. Import data & **library**"],"metadata":{"id":"GtcJ6mIvEhqf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnoOsCdeEFlC"},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"ND9pAQxiEObk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n","test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n","sub_df = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')"],"metadata":{"id":"nBK5f7vWEb9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')"],"metadata":{"id":"K3PXfk1LEeXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2. Exploratory Data Analysis"],"metadata":{"id":"U4SIfmxREpTx"}},{"cell_type":"markdown","source":["#### Simply watch the data"],"metadata":{"id":"2t_1OY8ZPSxl"}},{"cell_type":"code","source":["pd.set_option('display.max_rows', 50)\n","train_df.head(50)\n","train_df.head()"],"metadata":{"id":"sIefiwiyPaG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df.head()"],"metadata":{"id":"dBMl1XpMPccC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()\n","print('_'*40)\n","test_df.info()"],"metadata":{"id":"-MAtY_UHPdq2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Idenfity unique values, missing values, duplicated values"],"metadata":{"id":"r9O7qpxTPhwc"}},{"cell_type":"code","source":["def summary(df):\n","    summary = pd.DataFrame(index=df.columns)\n","    summary[\"Unique\"] = df.nunique().values\n","    summary[\"Missing\"] = df.isnull().sum()\n","    summary[\"Duplicated\"] = df.duplicated().sum()\n","    summary[\"Types\"] = df.dtypes\n","    return summary\n","\n","summary(train_df)"],"metadata":{"id":"GTNR_ySmPjvS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Feature classification\n","\n","**1. Categorical Features**\n","* HomePlanet, Destination: starting & destination planet\n","* CryoSleep: Whether a passenger was on CrypSleep or not\n","* VIP: Whether a user was on VIP or not\n","\n","**2. Numerical Features**\n","* Age: age of a passenger\n","* RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: charge for each service by one user\n","\n","**3. Descriptive Features**\n","* PassengerId: unique ID of a passenger\n","* Name: name of a passenger consist of first name and family name\n","* Cabin: number of cabin where a passenger lived\n","\n","**4. Target**\n","* Transported: boolean value, whether a passenger is transported or not"],"metadata":{"id":"KSz8VTQ_PnOl"}},{"cell_type":"markdown","source":["#### Statistics of numerical values"],"metadata":{"id":"nSKSEHTePq48"}},{"cell_type":"code","source":["train_df.describe()"],"metadata":{"id":"_Slb7wSZPsoV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualization of Categorical features"],"metadata":{"id":"3Hxo9WrlPxPO"}},{"cell_type":"code","source":["fig = plt.figure(figsize=[8,7])\n","\n","for i, var_name in enumerate(['HomePlanet', 'Destination', 'CryoSleep', 'VIP']):\n","    ax = fig.add_subplot(2, 2, i+1)\n","    sns.countplot(data = train_df, x = var_name, hue = 'Transported', axes=ax)\n","\n","fig.tight_layout()\n","plt.show()\n","\n","#HomePlanet, Destination, CyroSleep, VIP"],"metadata":{"id":"Uu-VZY6vPy94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Passengers who were in CryoSleep have transported more"],"metadata":{"id":"XyWV996gP2D6"}},{"cell_type":"markdown","source":["### Visualization of Numerical features"],"metadata":{"id":"-UXH8af_P4BB"}},{"cell_type":"markdown","source":["#### Is there a correlation between age & **transported**"],"metadata":{"id":"itwbhXX9P6Oo"}},{"cell_type":"code","source":["sns.displot(data = train_df, x = 'Age', hue = 'Transported', binwidth = 10)"],"metadata":{"id":"cP34yakRP6F9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> age group [0-10], [10-20] are more transported\n","\n","> age group [20-30], [30-40] are less transported"],"metadata":{"id":"umvEi1OeQFcm"}},{"cell_type":"markdown","source":["#### Is there a correlation between services & transported\n","\n","---\n","\n"],"metadata":{"id":"Onf6aJUiQHli"}},{"cell_type":"code","source":["fig = plt.figure(figsize=[10,16])\n","cat_feat = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n","for i, var_name in enumerate(cat_feat):\n","    ax = fig.add_subplot(5, 2, i*2+1)\n","    sns.histplot(data = train_df, x = var_name, hue = 'Transported', bins = 30)\n","\n","for i, var_name in enumerate(cat_feat):\n","    ax = fig.add_subplot(5, 2, i*2+2)\n","    sns.histplot(data = train_df,x = var_name,hue = 'Transported', bins = 30)\n","    plt.ylim(0, 400)\n","\n","fig.tight_layout()\n","plt.show()"],"metadata":{"id":"kMrxueUFQPx9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> RoomService, Spa, VRDeck: Passengers who spent less have transported more\n","\n","> FoodCourt, ShoppingMall: Passengers who spent more have transported more"],"metadata":{"id":"UIX9AtH3QR5L"}},{"cell_type":"markdown","source":["# 3. Feature Engineering"],"metadata":{"id":"ZkGwszSXQVWl"}},{"cell_type":"markdown","source":["### Create Group, GroupSize, Solo from PassengerID"],"metadata":{"id":"U9Ecru3jHRpd"}},{"cell_type":"code","source":["train_df['PassengerId']\n","# 숫자 'gggg_pp' 포맷으로 되어있음. gggg는 그룹, pp는 그룹 내 침대 번호."],"metadata":{"id":"bbIiO2BWHU5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get Group from PassengerId\n","train_df['Group'] = train_df['PassengerId'].apply(lambda x : x.split('_')[0])\n","test_df['Group'] = test_df['PassengerId'].apply(lambda x : x.split('_')[0])"],"metadata":{"id":"eeyy-3UqHV4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get GroupSize\n","train_df['GroupSize'] = train_df['Group'].apply(lambda x : train_df['Group'].value_counts()[x])\n","test_df['GroupSize'] = test_df['Group'].apply(lambda x : test_df['Group'].value_counts()[x])"],"metadata":{"id":"FfQxq77uHY3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get Solo whether passengers were traveling alone\n","train_df['Solo'] = train_df['GroupSize'].apply(lambda x : 1 if x == 1 else 0)\n","test_df['Solo'] = test_df['GroupSize'].apply(lambda x : 1 if x == 1 else 0)"],"metadata":{"id":"JVH_dQjDHcJl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Is there a correlation between GroupSize & Transported?\n","sns.countplot(data = train_df, x = 'GroupSize', hue = 'Transported')"],"metadata":{"id":"IHF-zdx0HiNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Is there a correlation between Solo & Transported?\n","sns.countplot(data = train_df, x = 'Solo', hue = 'Transported')"],"metadata":{"id":"vyaQQ3zUHlz_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create FamilyName, FamilySize from Name"],"metadata":{"id":"IIdSkElaHs8k"}},{"cell_type":"code","source":["train_df['Name']"],"metadata":{"id":"J_J2NB5YHv5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get FamilyName\n","train_df['FamilyName'] = train_df['Name'].apply(lambda x : x.split(' ')[1] if type(x) == str else x)\n","test_df['FamilyName'] = test_df['Name'].apply(lambda x : x.split(' ')[1] if type(x) == str else x)"],"metadata":{"id":"5Ce8wzgCHzxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get FamilySize\n","train_df['FamilySize'] = train_df['FamilyName'].apply(lambda x : train_df['FamilyName'].value_counts()[x] if x not in [np.nan] else x)\n","test_df['FamilySize'] = test_df['FamilyName'].apply(lambda x : test_df['FamilyName'].value_counts()[x] if x not in [np.nan] else x)"],"metadata":{"id":"-66qwHYYH6jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.countplot(data = train_df, x = 'FamilySize',hue = 'Transported')\n","#Is there a correlation between FamilySize & Transported?"],"metadata":{"id":"tzBgT-GjH9Hp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Is there a correlation between GroupSize & FamilySize?\n","train_df[['GroupSize', 'FamilySize']].corr(method='pearson', min_periods=1)"],"metadata":{"id":"4xzhmdwSH_62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create Cabin_deck, Cabin_num, Cabin_side from Cabin"],"metadata":{"id":"-X1_0TKkIFH5"}},{"cell_type":"code","source":["train_df['Cabin']"],"metadata":{"id":"Zoddpx23IHIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get deck, num, side from Cabin\n","\n","def deck(x):\n","    try:\n","        return x.split('/')[0]\n","    except:\n","        pass\n","\n","def num(x):\n","    try:\n","        return int(x.split('/')[1])\n","    except:\n","        pass\n","\n","def side(x):\n","    try:\n","        return x.split('/')[2]\n","    except:\n","        pass\n","\n","train_df['Cabin_deck'] = train_df['Cabin'].apply(deck)\n","train_df['Cabin_num'] = train_df['Cabin'].apply(num)\n","train_df['Cabin_side'] = train_df['Cabin'].apply(side)\n","\n","test_df['Cabin_deck'] = test_df['Cabin'].apply(deck)\n","test_df['Cabin_num'] = test_df['Cabin'].apply(num)\n","test_df['Cabin_side'] = test_df['Cabin'].apply(side)"],"metadata":{"id":"iI_CJlD6IH1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cabin = train_df.groupby(['Cabin_side', 'Cabin_deck'])['Cabin_num'].count().unstack()\n","cabin"],"metadata":{"id":"lt0RsZuDIM29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Is there a correlation between Cabin_deck & Transported?\n","sns.countplot(data = train_df, x = 'Cabin_deck',\n","              order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'], hue = 'Transported')"],"metadata":{"id":"kCzw_RfBIPrv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Is there a correlation between Cabin_num & Transported?\n","plt.figure(figsize=[9, 7])\n","\n","sns.histplot(data = train_df, x = 'Cabin_num', hue = 'Transported',\n","            bins = 19, binrange = (1, 1900)).set_xticks(range(0, 1900, 100))"],"metadata":{"id":"NQ17xjbYIS6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.countplot(data = train_df, x = 'Cabin_side', hue = 'Transported')"],"metadata":{"id":"j0LS9nPpIWQQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create TotalSpent, NoSpend"],"metadata":{"id":"C4Y1FybPIZ9d"}},{"cell_type":"code","source":["#Get TotalSpent\n","train_df['TotalSpent'] = train_df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n","test_df['TotalSpent'] = test_df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)"],"metadata":{"id":"i-hgHHOhIb7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.histplot(data = train_df, x = 'TotalSpent', hue = 'Transported')"],"metadata":{"id":"R1dwB6FUIg35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get NoSpend\n","train_df['NoSpend'] = train_df['TotalSpent'].apply(lambda x : True if x == 0.0 else False)\n","test_df['NoSpend'] = test_df['TotalSpent'].apply(lambda x : True if x == 0.0 else False)"],"metadata":{"id":"hN4lK0H9IjaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.countplot(data = train_df, x = 'NoSpend', hue = 'Transported')"],"metadata":{"id":"9GssXtnTIlYz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Preprocessing"],"metadata":{"id":"RHpK2tvjIrQv"}},{"cell_type":"markdown","source":["### Fill Missing values"],"metadata":{"id":"zxoIDdxAIsGZ"}},{"cell_type":"code","source":["# Concat train_df and test_df to handle missing value easily\n","df = pd.concat([train_df, test_df]).reset_index(drop=True)\n","df"],"metadata":{"id":"0IB2cZbpIuod"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### HomePlanet"],"metadata":{"id":"d3Am58mVIyQR"}},{"cell_type":"code","source":["df['HomePlanet'].isna().sum()"],"metadata":{"id":"PdyWsPbpI0Nk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#HomePlanet마다 Cabin_deck이 나누어져 있을 수도 있지 않을까?\n","train_df.groupby(['Cabin_deck'])['HomePlanet'].value_counts()\n","#A, B, C, T에는 Europa 출발 승객들만 탑승\n","#G에는 Earth 출발 승객들만 탑승"],"metadata":{"id":"UBtAD6xTI2ED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#따라서 결측값 중에 Cabin_deck이 A, B, C인 승객의 HomePlanet은 Europa로,\n","#Cabin_deck이 G인 승객의 HomePlanet은 Earth로 채우는 것이 타당함\n","print('처리 전 결측치 수  : ', df['HomePlanet'].isna().sum())\n","\n","for idx in df['HomePlanet'][df['HomePlanet'].isna() == True].index:\n","    if df.loc[idx, 'Cabin_deck'] in ['A', 'B', 'C']:\n","        df.loc[idx, 'HomePlanet'] = 'Europa'\n","    elif df.loc[idx, 'Cabin_deck'] in ['G']:\n","        df.loc[idx, 'HomePlanet'] = 'Earth'\n","\n","print('처리 후 결측치 수  : ', df['HomePlanet'].isna().sum())"],"metadata":{"id":"BNCXSEZiI4I9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.groupby(['Group'])['HomePlanet'].nunique().value_counts()\n","#같은 Group의 승객은 HomePlanet이 같다."],"metadata":{"id":"8Hk7Fw8nI6YD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#결측값 중 같은 Group의 승객의 HomePlanet이 판명된 경우, 같은 값으로 채웠다.\n","print('처리 전 결측치 수  : ', df['HomePlanet'].isna().sum())\n","\n","for idx in df['HomePlanet'][df['HomePlanet'].isna() == True].index:\n","    try:\n","        df.loc[idx, 'HomePlanet'] = [i for i in df[df['Group'] == df.loc[idx, 'Group']]['HomePlanet'].values if i not in [np.nan]][0]\n","    except:\n","        continue\n","\n","print('처리 후 결측치 수  : ', df['HomePlanet'].isna().sum())"],"metadata":{"id":"SppxQHM7I83w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.groupby(['FamilyName'])['HomePlanet'].nunique().value_counts()\n","#같은 FamilyName의 승객은 HomePlanet이 같다."],"metadata":{"id":"i-jb4Ty1I-gg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#결측값 중 같은 FamilyName의 승객의 HomePlanet이 판명된 경우, 같은 값으로 채웠다.\n","print('처리 전 결측치 수  : ', df['HomePlanet'].isna().sum())\n","\n","for idx in df['HomePlanet'][df['HomePlanet'].isna() == True].index:\n","    try:\n","        df.loc[idx, 'HomePlanet'] = [i for i in df[df['FamilyName'] == df.loc[idx, 'FamilyName']]['HomePlanet'].values if i not in [np.nan]][0]\n","    except:\n","        continue\n","\n","print('처리 후 결측치 수  : ', df['HomePlanet'].isna().sum())"],"metadata":{"id":"5tQD-GQnJAMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#남은 결측값들을 보자.\n","df.loc[df['HomePlanet'][df['HomePlanet'].isna() == True].index]\n","#모두 혼자 여행하며, 데크 'F', 'D', 'E'에 탑승한 'TRAPPIST-1e'행 non-VIP 승객들이다."],"metadata":{"id":"RldYI0STJCws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.groupby(['HomePlanet'])['Destination'].value_counts().unstack()"],"metadata":{"id":"trnJ2LNJJEse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df[train_df['Destination'] == 'TRAPPIST-1e'].groupby(['HomePlanet', 'Cabin_side'])['Cabin_deck'].value_counts().unstack().fillna(0)"],"metadata":{"id":"8dOHK9_RJGj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#남은 결측값은 'Earth'로 채운다.\n","print('처리 전 결측치 수  : ', df['HomePlanet'].isna().sum())\n","\n","df.loc[df[df['HomePlanet'].isna() == True].index, 'HomePlanet'] = 'Earth'\n","\n","print('처리 후 결측치 수  : ', df['HomePlanet'].isna().sum())"],"metadata":{"id":"JGdzMhv-JI2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Destination"],"metadata":{"id":"wmjVOhWSJOgN"}},{"cell_type":"code","source":["df['Destination'].isna().sum()"],"metadata":{"id":"2QG8KiGSJQCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TRAPPIST-1e 행 승객의 비율이 가장 많으므로, TRAPPIST-1e로 채운다. (더 좋은 룰을 발견하지 못했음..)\n","print('처리 전 결측치 수  : ', df['Destination'].isna().sum())\n","\n","df['Destination'] = df['Destination'].fillna('TRAPPIST-1e')\n","\n","print('처리 후 결측치 수  : ', df['Destination'].isna().sum())"],"metadata":{"id":"iaig5WW-JRrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####CryoSleep"],"metadata":{"id":"2Ps2jcloJUfu"}},{"cell_type":"code","source":["#GroupSize가 2 이상인 승객 중, Group이 같으면, CryoSleep도 같은가?\n","print(train_df[train_df['GroupSize'] > 1].groupby(['Group'])['CryoSleep'].nunique().value_counts())\n","\n","#GroupSize가 2 이상인 승객 중, Cabin이 같으면, CryoSleep도 같은가?\n","print(train_df[train_df['GroupSize'] > 1].groupby(['Cabin'])['CryoSleep'].nunique().value_counts())\n","\n","#그렇지는 않다."],"metadata":{"id":"6oyg3ItYJW1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('전체 승객들 중 TotalSpent가 0인 비율             : ', len(train_df[train_df['TotalSpent'] == 0]) / len(train_df))\n","print('TotalSpent가 0인 승객들 중 CryoSleep == True 비율: ', len(train_df[train_df['CryoSleep'] == True]) / len(train_df[train_df['TotalSpent'] == 0]))"],"metadata":{"id":"zYDgih77JaF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#결측값 중 TotalSpent == 0인 승객들은 True로, 아닌 승객들은 False로 채운다.\n","print('처리 전 결측치 수  : ', df['CryoSleep'].isna().sum())\n","\n","df.loc[df['TotalSpent'] == 0, 'CryoSleep'] = df.loc[df['TotalSpent'] == 0, 'CryoSleep'].fillna(True)\n","df.loc[df['TotalSpent'] > 0, 'CryoSleep'] = df.loc[df['TotalSpent'] > 0, 'CryoSleep'].fillna(False)\n","\n","print('처리 후 결측치 수  : ', df['CryoSleep'].isna().sum())"],"metadata":{"id":"DM-JmiSUJcQ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Cabin"],"metadata":{"id":"_5yEcOo5JhR5"}},{"cell_type":"code","source":["df['Cabin'].isna().sum()"],"metadata":{"id":"EqrQFJyCJjGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#HomePlanet 별 Cabin_deck, Cabin_num 분포를 보자.\n","\n","fig = plt.figure(figsize=[6,15])\n","\n","for i, var_name in enumerate(['Europa', 'Mars', 'Earth']):\n","    ax = fig.add_subplot(3, 1, i+1).set_title(var_name)\n","    sns.histplot(data = train_df[train_df['HomePlanet'] == var_name],\n","                x = 'Cabin_num',\n","                hue = 'Cabin_deck',\n","                multiple = 'stack',\n","                bins = 19,\n","                binrange = (1, train_df['Cabin_num'].max()),\n","                hue_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'],\n","                palette = sns.color_palette('Set3')).set_xticks(range(0, 1900, 100))\n","\n","\n","fig.tight_layout()\n","plt.show()\n","\n","#Europa 출신 승객부터 Mars 출신 승객, Earth 출신 승객들을 알파벳 순대로, 앞 번호부터 태웠음을 알 수 있다.\n","#'A', 'B', 'C', 'D', 'E'에는 Europa, 'D', 'E', 'F'에는 Mars, 'D', 'E', 'F', 'G'에는 Earth"],"metadata":{"id":"tLmwLBmQJmbQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Cabin_deck"],"metadata":{"id":"-7ilLQZjJvSn"}},{"cell_type":"code","source":["df['Cabin_deck'].isna().sum()"],"metadata":{"id":"ZKbl-xi9Jwug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GroupSize가 2 이상인 승객들 중, Group이 같은 승객들은, Cabin_deck도 같은가?\n","print(train_df[train_df['GroupSize'] > 1].groupby(['Group'])['Cabin_deck'].nunique().value_counts())\n","\n","#FamilySize가 2 이상인 승객들 중, FamilyName이 같은 승객들은, Cabin_deck도 같은가?\n","print(train_df[train_df['FamilySize'] > 1].groupby(['FamilyName'])['Cabin_deck'].nunique().value_counts())\n","\n","#HomePlanet과 같은 방식으로는 채울 수 없을 것 같다."],"metadata":{"id":"7GOQI2k2JyQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df[(train_df['HomePlanet'] == 'Earth') & (train_df['CryoSleep'] == True)]['Cabin_deck'].value_counts()\n","#'Earth' 출신의 CryoSleep == True 중의 절대다수는 deck 'G'에 탑승"],"metadata":{"id":"fYuagM_0Jz-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#해당 결측치를 'G'로 채워준다.\n","print('처리 전 결측치 수  : ', df['Cabin_deck'].isna().sum())\n","\n","df.loc[df[(df['HomePlanet'] == 'Earth') & (df['CryoSleep'] == True) & (df['Cabin_deck'].isna() == True)].index, 'Cabin_deck'] = 'G'\n","\n","print('처리 후 결측치 수  : ', df['Cabin_deck'].isna().sum())"],"metadata":{"id":"fXXtNehbJ12T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#나머지는 HomePlanet, Destination, Solo에 따라 서브그룹을 나누었을 때, 각 서브그룹 별 최빈값으로 채워주었다.\n","print('처리 전 결측치 수  : ', df['Cabin_deck'].isna().sum())\n","\n","ct1_nan_index = df.loc[df['Cabin_deck'].isna()].index\n","df.loc[df['Cabin_deck'].isna(), 'Cabin_deck'] = df.groupby(['HomePlanet', 'Destination', 'Solo'])['Cabin_deck'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))[ct1_nan_index]\n","\n","print('처리 후 결측치 수  : ', df['Cabin_deck'].isna().sum())"],"metadata":{"id":"plUe17BnJ3sC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Cabin_num"],"metadata":{"id":"Qm0rqmgaJ6U0"}},{"cell_type":"code","source":["df['Cabin_num'].isna().sum()"],"metadata":{"id":"0NQZKcNmJ78f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GroupSize가 2 이상인 승객들 중, Group이 같은 승객들은, Cabin_num도 같은가?\n","print(train_df[train_df['GroupSize'] > 1].groupby(['Group'])['Cabin_num'].nunique().value_counts())\n","\n","#FamilySize가 2 이상인 승객들 중, FamilyName이 같은 승객들은, Cabin_num도 같은가?\n","print(train_df[train_df['FamilySize'] > 1].groupby(['FamilyName'])['Cabin_num'].nunique().value_counts())\n","\n","#그렇지는 않다."],"metadata":{"id":"v-1mvbd9J9rr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LinearRegression\n","\n","model_LE1 = LabelEncoder()\n","\n","#plt.figure(figsize=(10,4))\n","#sns.scatterplot(x=train_df['Cabin_num'], y=train_df['Group'], c=model_LE1.fit_transform(train_df.loc[~train_df['Cabin_num'].isna(),'Cabin_deck']))\n","#plt.title('Cabin_num - Group')"],"metadata":{"id":"B1LA_q_mKCgL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('처리 전 결측치 수  : ', df['Cabin_num'].isna().sum())\n","\n","for deck in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:  #T는 결측값이 5개 뿐이므로 제외한다.\n","\n","    #이미 다 채워져있는 deck는 계속 진행 시 모델예측 부분에서 오류가 난다. continue해주자\n","    if len(df.loc[(df['Cabin_num'].isna()) & (df['Cabin_deck']==deck)]) ==0:\n","        continue\n","    # Cabin_num가 결측치가 아닌 Group number를 X_train으로 넣어주고\n","    X_CN_train = df.loc[~(df['Cabin_num'].isna()) & (df['Cabin_deck']==deck),'Group']\n","    # Cabin_num가 결측치가 아닌 Cabin_num를 y_train으로 넣어준다.\n","    y_CN_train = df.loc[~(df['Cabin_num'].isna()) & (df['Cabin_deck']==deck),'Cabin_num']\n","    # Cabin_num가 \"결측치인\" Group number를 X_test로 넣어준다.\n","    # 이는 결측치를 채울 '우리 모델의 예측값을 뽑아낼때' 필요한 값이다.\n","    X_CN_test = df.loc[(df['Cabin_num'].isna()) & (df['Cabin_deck']==deck),'Group']\n","\n","    #모델 학습 및 결측치 예상값을 pred_LR1 에 할당\n","    model_LR1=LinearRegression()\n","    model_LR1.fit(X_CN_train.values.reshape(-1, 1), y_CN_train)\n","    pred_LR1 = model_LR1.predict(X_CN_test.values.reshape(-1, 1))\n","\n","    df.loc[(df['Cabin_num'].isna()) & (df['Cabin_deck']==deck),'Cabin_num']=pred_LR1.astype(int)\n","\n","print('처리 후 결측치 수  : ', df['Cabin_num'].isna().sum())"],"metadata":{"id":"WzGq-9SFKEyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=[9, 7])\n","\n","sns.histplot(data = train_df, x = 'Cabin_num', hue = 'Transported',\n","            bins = 19, binrange = (1, 1900)).set_xticks(range(0, 1900, 100))"],"metadata":{"id":"PNCcERR-KILS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Cabin_num_Group'] = np.nan\n","df.loc[df['Cabin_num'] < 300, 'Cabin_num_Group'] = 0\n","df.loc[(df['Cabin_num'] >= 300) & (df['Cabin_num'] < 600), 'Cabin_num_Group'] = 1\n","df.loc[(df['Cabin_num'] >= 600) & (df['Cabin_num'] < 900), 'Cabin_num_Group'] = 2\n","df.loc[(df['Cabin_num'] >= 900) & (df['Cabin_num'] < 1200), 'Cabin_num_Group'] = 3\n","df.loc[(df['Cabin_num'] >= 1200) & (df['Cabin_num'] < 1500), 'Cabin_num_Group'] = 4\n","df.loc[df['Cabin_num'] >= 1500, 'Cabin_num_Group'] = 5\n","df['Cabin_num_Group']"],"metadata":{"id":"uAFVJ7cxKKK0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Cabin_side"],"metadata":{"id":"LqwsMH5IKNIN"}},{"cell_type":"code","source":["df['Cabin_side'].isna().sum()"],"metadata":{"id":"IFWJKEYqKPDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GroupSize가 2 이상인 승객들 중, Group이 같은 승객들은, Cabin_side도 같은가?\n","print(train_df[train_df['GroupSize'] > 1].groupby(['Group'])['Cabin_side'].nunique().value_counts())"],"metadata":{"id":"SruOspLTKRdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#같은 Group의 사람들의 Cabin_side를 같도록 채운다.\n","print('처리 전 결측치 수  : ', df['Cabin_side'].isna().sum())\n","\n","for idx in df['Cabin_side'][df['Cabin_side'].isna() == True].index:\n","    try:\n","        df.loc[idx, 'Cabin_side'] = [i for i in df[df['Group'] == df.loc[idx, 'Group']]['Cabin_side'].values if i not in [np.nan]][0]\n","    except:\n","        continue\n","\n","print('처리 후 결측치 수  : ', df['Cabin_side'].isna().sum())"],"metadata":{"id":"0KdLK-7fKTpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#FamilySize가 2 이상인 승객들 중, FamilyName이 같은 승객들은, Cabin_side도 같은가?\n","print(train_df[train_df['FamilySize'] > 1].groupby(['FamilyName'])['Cabin_side'].nunique().value_counts())\n","#그렇지는 않다."],"metadata":{"id":"sXK4e3A4KVZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#더 이상 다른 규칙을 발견하지 못했으므로, 남은 결측치는 Unknown으로 치자.\n","print('처리 전 결측치 수  : ', df['Cabin_side'].isna().sum())\n","\n","for idx in df['Cabin_side'][df['Cabin_side'].isna() == True].index:\n","    try:\n","        df.loc[idx, 'Cabin_side'] = 'Unknown'\n","    except:\n","        continue\n","\n","print('처리 후 결측치 수  : ', df['Cabin_side'].isna().sum())"],"metadata":{"id":"fugV_1hyKXn9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####VIP"],"metadata":{"id":"d_llROGuKkGj"}},{"cell_type":"code","source":["df['VIP'].isna().sum()"],"metadata":{"id":"mMNASATTKpzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.countplot(data = train_df, x='HomePlanet', hue = 'VIP')"],"metadata":{"id":"tx7JkCfjKrTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전체 인원별 VIP수가 2% 밖에 안되어, 모두 False로 채운다\n","print('처리 전 결측치 수  : ', df['VIP'].isna().sum())\n","\n","for idx in df['VIP'][df['VIP'].isna() == True].index:\n","    try:\n","        df.loc[idx, 'VIP'] = False\n","    except:\n","        continue\n","\n","print('처리 후 결측치 수  : ', df['VIP'].isna().sum())"],"metadata":{"id":"SW8PYC77Ks4N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Age"],"metadata":{"id":"tldbAsCDKwcj"}},{"cell_type":"code","source":["sns.displot(data = train_df, x='Age', hue = \"Solo\", kind=\"kde\", alpha = 0.5)\n","# 어린 아이들은 혼자가 아닌 비율이 높음"],"metadata":{"id":"znKeh2DNKyTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.displot(data = train_df, x='Age', hue=\"NoSpend\", kind=\"kde\", alpha = 0.5)\n","#어린 아이들은 스스로 돈을 지불하지 않은 비율이 높음"],"metadata":{"id":"4lcdx5-5K0QV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.displot(data= train_df, x='Age', hue=\"Cabin_deck\", kind=\"kde\", alpha = 0.5)\n","#deck별 나이 분포도. 조금의 차이가 있음"],"metadata":{"id":"Vt9NvQC7K1xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.displot(data=train_df, x='Age', hue=\"HomePlanet\", kind=\"kde\", alpha = 0.5)\n","#출신 행성별 나이 분포도또한 유의미한 차이가 있음. Earth에서 온 승객들이 젊은 사람의 비율이 높음"],"metadata":{"id":"GNjDAwP5K4CX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 위에서 살펴본 4개 feature(Solo, NoSpend,Cabin_deck, HomePlanet)가 age와의 상관관계가 있음\n","\n","* age의 결측치를 더 정밀하:게 채워주려면 위 4개 feature의 조합을 고려해(서브그룹화)\n","  각 서브그룹별 평균값(혹은 중간값)을 결측값으로 대입\n","  \n","    평균값과 중간값은 큰 차이는 없으나 중간값이 좀 더 큰 값을 보여줌\n","    특이구간은 20세 미만에서 많이 관측되었기에, 좀 더 큰 값인 중간값을 사용"],"metadata":{"id":"SUdObvRmLBhu"}},{"cell_type":"code","source":["print('처리 전 결측치 수  : ', df['Age'].isna().sum())\n","\n","table8 = df.groupby(['HomePlanet','NoSpend','Solo','Cabin_deck'])['Age'].median().unstack().fillna(0)\n","age_table_index = table8.index\n","age_table_columns = table8.columns\n","\n","for deck in age_table_columns:\n","    cond_deck = df['Cabin_deck'] == deck\n","    for idx in age_table_index:\n","        cond0 = df['Age'].isna()\n","        cond1 = df['HomePlanet'] == idx[0]\n","        cond2 = df['NoSpend'] == idx[1]\n","        cond3 = df['Solo'] == idx[2]\n","\n","        df.loc[cond0&cond1&cond2&cond3&cond_deck,'Age'] = df.loc[cond0&cond1&cond2&cond3&cond_deck,'Age'].fillna(table8.loc[idx][deck])\n","    #df.loc[df.Age.isna(),'Age'] =\n","\n","print('처리 후 결측치 수  : ', df['Age'].isna().sum())"],"metadata":{"id":"YTKLIYrzLLSL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Turn Age to Categorical value"],"metadata":{"id":"MaxuRpe1Lchc"}},{"cell_type":"code","source":["fig = plt.figure(figsize=[30, 8])\n","\n","fig = sns.displot(data = train_df, x = 'Age', hue = 'Transported', binwidth = 2)\n","plt.show\n","#나이대별로 일정 '구간단위'로 Target값의 상관관계가 역전됨. 적절한 구간을 두면 정확도가 더 상승할 것."],"metadata":{"id":"12EkPgLrLfKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Age_Group'] = np.nan # 초기화\n","df.loc[df['Age']<=12,'Age_Group']='0-12'\n","df.loc[(df['Age']>12) & (df['Age']<18),'Age_Group']='13-17'\n","df.loc[(df['Age']>=18) & (df['Age']<=25),'Age_Group']='18-25'\n","df.loc[(df['Age']>25) & (df['Age']<=30),'Age_Group']='26-30'\n","df.loc[(df['Age']>30) & (df['Age']<=50),'Age_Group']='31-50'\n","df.loc[df['Age']>50,'Age_Group']='51+'\n","df['Age_Group']"],"metadata":{"id":"Wd4g79ecLhMy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### RoomService, FoodCourt, ShoppingMall, Spa, VRDeck"],"metadata":{"id":"Gsk3zDcKLkL-"}},{"cell_type":"code","source":["luxury = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"],"metadata":{"id":"4etPz94DLptx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[luxury].isna().sum()"],"metadata":{"id":"X7uDCqxzLrWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.loc[df[df['CryoSleep'] == True].index, luxury].isna().sum()\n","#CryoSleep == True인 승객들 중의 결측치 수"],"metadata":{"id":"UbnmVfDqLtBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#CryoSleep == True인 승객들의 결측치는 0으로\n","print('처리 전 결측치 수  : \\n', df[luxury].isna().sum(), sep='')\n","\n","df.loc[df[df['CryoSleep'] == True].index, luxury] = df.loc[df[df['CryoSleep'] == True].index, luxury].fillna(0)\n","\n","print('처리 후 결측치 수  : \\n', df[luxury].isna().sum(), sep='')"],"metadata":{"id":"BpCQpZ_-Lu2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#각 서비스 소비금액은 HomePlanet, Destination, Solo, VIP, Cabin_deck에 따라 다른 분포를 보이므로,\n","#해당 서브그룹들의 평균값으로 채워주었다.\n","\n","for feature in luxury:\n","    table = df.groupby(['HomePlanet','Destination','Solo','VIP','Cabin_deck'])[feature].mean().unstack().fillna(0)\n","    for planet, destination, solo, vip in table.index:\n","        for deck in table.columns:\n","            #결측치 위치 호출 위한 조건들 저장\n","            cond1 = df['HomePlanet'] == planet\n","            cond2 = df['Destination'] == destination\n","            cond3 = df['Solo'] == solo\n","            cond4 = df['VIP'] == vip\n","            #결측치 채울 값 : mean_value\n","            mean_value = table.loc[(planet, destination, solo, vip)][deck]\n","            df.loc[cond1&cond2&cond3&cond4, feature] = df.loc[cond1&cond2&cond3&cond4, feature].fillna(mean_value)\n","\n","print('처리 후 결측치 수  : \\n', df[luxury].isna().sum(), sep='')"],"metadata":{"id":"0iPqTll6LxnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#채워진 데이터로 TotalExpenditure와 NoSpending을 업데이트\n","df['TotalSpent'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n","df['NoSpend'] = df['TotalSpent'].apply(lambda x : True if x == 0.0 else False)\n","df[['TotalSpent', 'NoSpend']].info()"],"metadata":{"id":"VEZjjV1nLzYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#EDA할 때 봤었던 대로, (RoomService, Spa, VRDeck)과 (FoodCourt, ShoppingMall)이 다른 분포를 보이기 때문에\n","#각각을 묶는 변수도 하나 만들어 주면 활용할 수 있을 것 같다.\n","df['Spend_luxury'] = df[['RoomService', 'Spa', 'VRDeck']].sum(axis=1)\n","df['Spend_necessary'] = df[['FoodCourt', 'ShoppingMall']].sum(axis=1)\n","df[['Spend_luxury', 'Spend_necessary']].info()"],"metadata":{"id":"cLgyT9dSL1X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().sum()"],"metadata":{"id":"SXFckbDfL3MS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#다시 train set과 test set을 분리\n","train_df = df[df['PassengerId'].isin(train_df['PassengerId']).values == True]\n","test_df = df[df['PassengerId'].isin(test_df['PassengerId']).values == True].drop('Transported', axis=1)"],"metadata":{"id":"7bOj9GxtL5lU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Converting object dtype to int dtype, by turning string to ordinal numerical value"],"metadata":{"id":"9q_yLOhGL-jY"}},{"cell_type":"code","source":["train_df['FamilySize'] = train_df['FamilySize'].fillna(0)\n","test_df['FamilySize'] = test_df['FamilySize'].fillna(0)"],"metadata":{"id":"MhPXNBFCMAYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"id":"4wjjoeyrMB2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CryoSleep_train = train_df['CryoSleep']\n","CryoSleep_test = test_df['CryoSleep']"],"metadata":{"id":"tjwpYDtmMDch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#nunique값이 너무 큰 object feature들 드랍,\n","#나머지 object feature는 numerical-ordinal의 int type으로 변형\n","obj_feature = ['PassengerId', 'Cabin', 'Name', 'Group', 'FamilyName', 'Cabin_num']\n","\n","train_df = train_df.drop(columns=obj_feature)\n","test_df = test_df.drop(columns=obj_feature)\n","\n","train_df['HomePlanet'] = train_df['HomePlanet'].map({'Earth': 0, 'Europa': 1, 'Mars': 2}).astype(int)\n","test_df['HomePlanet'] = test_df['HomePlanet'].map({'Earth': 0, 'Europa': 1, 'Mars': 2}).astype(int)\n","train_df['Destination'] = train_df['Destination'].map({'TRAPPIST-1e': 0, '55 Cancri e': 1, 'PSO J318.5-22': 2}).astype(int)\n","test_df['Destination'] = test_df['Destination'].map({'TRAPPIST-1e': 0, '55 Cancri e': 1, 'PSO J318.5-22': 2}).astype(int)"],"metadata":{"id":"-lIqGdQFMF2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"id":"ppoKTewhMIpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['CryoSleep'] = train_df['CryoSleep'].map({False: 0, True: 1})\n","test_df['CryoSleep'] = test_df['CryoSleep'].map({False: 0, True: 1})\n","train_df"],"metadata":{"id":"caA1KGlFMKMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['VIP'] = train_df['VIP'].map({False: 0, True: 1})\n","test_df['VIP'] = test_df['VIP'].map({False: 0, True: 1})\n","\n","train_df['Cabin_deck'] = train_df['Cabin_deck'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}).astype(int)\n","test_df['Cabin_deck'] = test_df['Cabin_deck'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}).astype(int)"],"metadata":{"id":"uF0DF-D5MNjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['Cabin_side'].value_counts()"],"metadata":{"id":"vk4Nbdn_MPl4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['Cabin_side'] = train_df['Cabin_side'].map({'P': 0, 'S': 1, 'Unknown': 2}).astype(int)\n","test_df['Cabin_side'] = test_df['Cabin_side'].map({'P': 0, 'S': 1, 'Unknown': 2}).astype(int)"],"metadata":{"id":"4khVwv9xMSEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train_df['Cabin_num_Group'] = train_df['Cabin_num_Group'].map({'-300': 0, '300-600': 1, '600-900': 2, '900-1200': 3, '1200-1500': 4})\n","#test_df['Cabin_num_Group'] = test_df['Cabin_num_Group'].map({'-300': 0, '300-600': 1, '600-900': 2, '900-1200': 3, '1200-1500': 4})\n","train_df['Age_Group'] = train_df['Age_Group'].map({'0-12': 0, '13-17': 1, '18-25': 2, '26-30': 3, '31-50': 4, '51+': 5}).astype(int)\n","test_df['Age_Group'] = test_df['Age_Group'].map({'0-12': 0, '13-17': 1, '18-25': 2, '26-30': 3, '31-50': 4, '51+': 5}).astype(int)\n","\n","train_df['NoSpend'] = train_df['NoSpend'].map({False: 0, True: 1}).astype(int)\n","test_df['NoSpend'] = test_df['NoSpend'].map({False: 0, True: 1}).astype(int)"],"metadata":{"id":"qkrPX3AGMVPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df"],"metadata":{"id":"kNK8-4gzMYQT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Prepare Train / Validation / Test"],"metadata":{"id":"6gvZwOmjN2k0"}},{"cell_type":"markdown","source":["#### first version of Train/Validation set"],"metadata":{"id":"BzXoSHNcN5Ht"}},{"cell_type":"code","source":["X = train_df.drop('Transported', axis=1)\n","y = train_df['Transported']"],"metadata":{"id":"vxDyYAC4N69Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### second version of Train/Validation set, dropping each spend feature, leaving spend_luxury, spend_necessary"],"metadata":{"id":"eqQMwRSoN9pv"}},{"cell_type":"code","source":["X1 = X.drop(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpent'], axis=1)\n","summary(X1)"],"metadata":{"id":"NMRGeY_wN_-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = y.apply(lambda x : 1 if x == True else 0)\n","y"],"metadata":{"id":"-i79SN0OOB4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split as tts\n","X_train, X_val, y_train, y_val = tts(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"QOL6WY1wOD4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X1_train, X1_val, y1_train, y1_val = tts(X1, y, test_size=0.2, random_state=42)"],"metadata":{"id":"-dFpKlFwOGOT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Model selection"],"metadata":{"id":"UkbUHSL8OInj"}},{"cell_type":"code","source":["#from sklearn.tree import DecisionTreeClassifier\n","#dtc = DecisionTreeClassifier()\n","#dtc.fit(X_train, y_train)\n","#print(dtc.score(X_train, y_train))\n","#print(dtc.score(X_val, y_val))"],"metadata":{"id":"sfbfqta_OLII"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Simply applied to single model, **DecisionTree**"],"metadata":{"id":"I1u3xCQEO_gr"}},{"cell_type":"code","source":["dtc = DecisionTreeClassifier()\n","dtc.fit(X1_train, y1_train)\n","print(dtc.score(X1_train, y1_train))\n","print(dtc.score(X1_val, y1_val))"],"metadata":{"id":"WotFk_jGO70n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Tried various models"],"metadata":{"id":"zOjoDokaPJR0"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","\n","lr = LogisticRegression()\n","svc = SVC()\n","svclin = LinearSVC()\n","tree = DecisionTreeClassifier()\n","rftree = RandomForestClassifier()\n","ada = AdaBoostClassifier()\n","gbc = GradientBoostingClassifier()\n","\n","models = {'Logistic Regression' : lr,\n","         'SVC' : svc,\n","         'Linear SVC' : svclin,\n","         'Decision Tree' : tree,\n","         'Random Forest' : rftree,\n","         'Ada Boost' : ada,\n","         'Gradient Boost' : gbc}"],"metadata":{"id":"jk4lP693PNxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for key, model in models.items():\n","#    model.fit(X_train, y_train)"],"metadata":{"id":"s9EsSb5XPU2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, model in models.items():\n","    model.fit(X1_train, y1_train)"],"metadata":{"id":"UeWSyZwEPWO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for key, model in models.items():\n","#\n","#    print(key)\n","#    print('train : ', model.score(X_train, y_train))\n","#    print('test  : ', model.score(X_val, y_val))\n","#    print('')"],"metadata":{"id":"-kvq9_anPXoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, model in models.items():\n","\n","    print(key)\n","    print('train : ', model.score(X1_train, y1_train))\n","    print('test  : ', model.score(X1_val, y1_val))\n","    print('')"],"metadata":{"id":"cDrTNCkJPZXM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Tried Various Ensemble Model"],"metadata":{"id":"Nbc7wNGVPbUn"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from catboost import CatBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import (RandomForestClassifier,\n","                              AdaBoostClassifier, BaggingClassifier,\n","                              ExtraTreesClassifier, GradientBoostingClassifier)\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier"],"metadata":{"id":"xLq8egFtPfOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat = CatBoostClassifier(verbose = False)\n","rfc = RandomForestClassifier(max_depth = 5, random_state=42)\n","dtc = DecisionTreeClassifier(max_depth=5)\n","abc = AdaBoostClassifier(random_state=42)\n","bc = BaggingClassifier(random_state=42)\n","gbdt = GradientBoostingClassifier(learning_rate=0.05, max_depth=8, n_estimators=500,subsample=0.5213,random_state=42)\n","xgb = XGBClassifier('binary:logistic',colsample_bytree=0.4603, gamma=0.0468,\n","                             learning_rate=0.05, max_depth=5,\n","                             min_child_weight=1.7817, n_estimators=500,\n","                             reg_alpha=4.5, reg_lambda=8.5,\n","                             subsample=0.5213,\n","                             random_state=42)\n","lgb = LGBMClassifier()"],"metadata":{"id":"KRiPoGcIPhkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clfs = {\n","#     'LR': lrc,\n","    'CBC':cat,\n","    'RF': rfc,\n","    'DTC':dtc,\n","    'ABC':abc,\n","    'BC':bc,\n","    'GBDT':gbdt,\n","    'xgb':xgb,\n","    'LGB':lgb\n","}"],"metadata":{"id":"bdVv-L_cP1U9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from sklearn.model_selection import cross_val_score\n","#for name, clf in clfs.items():\n","#    print(f'for {name}, the cross_val_score is ')\n","#    print(np.mean(cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy')))\n","#    print('-'*30)"],"metadata":{"id":"aw4KHJqVP3n_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from sklearn.model_selection import cross_val_score\n","#for name, clf in clfs.items():\n","#    print(f'for {name}, the cross_val_score is ')\n","#    print(np.mean(cross_val_score(clf, X1_train, y1_train, cv = 5, scoring = 'accuracy')))\n","#    print('-'*30)"],"metadata":{"id":"kAat5Wi5P5A6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Voting Classifier"],"metadata":{"id":"W5mk4kDxP9jB"}},{"cell_type":"code","source":["bc = BaggingClassifier(n_estimators = 1100, random_state=42)\n","gbc = GradientBoostingClassifier(learning_rate=0.05, max_depth=8, n_estimators=800,subsample=0.5213,random_state=42)\n","cat = CatBoostClassifier(verbose = False)\n","lgb = LGBMClassifier()\n","xgb = XGBClassifier('binary:logistic',colsample_bytree=0.4603, gamma=0.0468,\n","                             learning_rate=0.05, max_depth=5,\n","                             min_child_weight=1.7817, n_estimators=1000,\n","                             reg_alpha=4.5, reg_lambda=8.5,\n","                             subsample=0.5213,\n","                             random_state=42)"],"metadata":{"id":"k74syF73P_ou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from sklearn.ensemble import VotingClassifier\n","#voting = VotingClassifier(estimators=[('lgb',lgb),('cat',cat),('xgb',xgb),('bc',bc),('gbc',gbc)],voting='soft')\n","#voting.fit(X_train,y_train)"],"metadata":{"id":"K6bqGyAJQBNX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#voting.fit(X1_train,y1_train)"],"metadata":{"id":"oeuphL5SQCzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#scores = []"],"metadata":{"id":"DacXGtxiQE02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#scores1 = []"],"metadata":{"id":"uPddNvsKQGVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y_pred = voting.predict(X_val)\n","#acc = accuracy_score(y_val,y_pred)\n","#scores.append(['with gbc', acc])\n","#print(\"Accuracy\",acc)"],"metadata":{"id":"Kw4qkfeGQH78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y1_pred = voting.predict(X1_val)\n","#acc = accuracy_score(y1_val,y1_pred)\n","#scores1.append(['with gbc', acc])\n","#print(\"Accuracy\",acc)"],"metadata":{"id":"3cBWhMQsQJ5p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Stacking Classifier"],"metadata":{"id":"v5PTp1bpQMiJ"}},{"cell_type":"code","source":["bc = BaggingClassifier(n_estimators=900, random_state=42)\n","cat = CatBoostClassifier(verbose = False)\n","lgb = LGBMClassifier()\n","xgb = XGBClassifier('binary:logistic',colsample_bytree=0.4603, gamma=0.0468,\n","                             learning_rate=0.05, max_depth=5,\n","                             min_child_weight=1.7817, n_estimators=1200,\n","                             reg_alpha=4.5, reg_lambda=8.5,\n","                             subsample=0.5213,\n","                             random_state=42)"],"metadata":{"id":"w82Gu6fmQOMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["estimators=[('lgb',lgb),('cat',cat),('bc', bc), ('xgb',xgb)]\n","final_estimator = GradientBoostingClassifier(learning_rate=0.05, max_depth=8, n_estimators=1000,subsample=0.5213,random_state=42)"],"metadata":{"id":"9p7G_HgWQQXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from sklearn.ensemble import StackingClassifier\n","#stacking = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n","#stacking.fit(X_train,y_train)"],"metadata":{"id":"-1GZqtIdQSKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#stacking.fit(X1_train,y1_train)"],"metadata":{"id":"1AlQ4nQXQTbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y_pred = stacking.predict(X_val)\n","#print(\"Accuracy\",accuracy_score(y_val,y_pred))"],"metadata":{"id":"DHXVOVAlQU4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y1_pred = stacking.predict(X1_val)\n","#print(\"Accuracy\",accuracy_score(y1_val,y1_pred))"],"metadata":{"id":"qnZipOPaQWIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#logistic regression을 위한 패러미터\n","lr_params = {'penalty' : ['l1', 'l2', 'elasticnet', None],\n","           'C' : [0.01, 0.1, 1, 10],\n","           'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n","\n","#svc를 위한 패러미터\n","svc_params = {'C' : [0.01, 0.1, 1, 10, 100, 200]}\n","\n","#linear svc를 위한 패러미터\n","svclin_params = {'penalty' : ['l1', 'l2'],\n","                 'loss' : ['hinge', 'squared_hinge'],\n","                 'C' : [0.01, 0.1, 1, 10]}\n","\n","#decision tree를 위한 패러미터\n","tree_params = {'criterion' : ['gini', 'entropy', 'log_loss'],\n","               'max_depth' : [5, 10, 20, 30, 40],\n","               'min_samples_split' : [2, 3, 4],\n","               'min_samples_leaf' : [1, 2, 3]}\n","#'n_estimators' : [100, 10, 50, 200],\n","\n","#random forest를 위한 패러미터\n","rftree_params = {'criterion' : ['gini', 'entropy', 'log_loss'],\n","              'max_depth' : [3, 2, 5, 10],\n","              'min_samples_split' : [2, 3, 4],\n","              'min_samples_leaf' : [1, 2, 3]}\n","\n","#ada boost를 위한 패러미터\n","ada_params = {'n_estimators' : [100, 10, 50, 200],\n","              'learning_rate' : [0.1, 0.01, 1]}\n","\n","#gradient boost를 위한 패러미터\n","gbc_params = {'n_estimators' : [100, 10, 50, 200],\n","              'learning_rate' : [0.1, 0.01, 1]}\n","\n","scorings = ['accuracy', 'f1', 'roc_auc']"],"metadata":{"id":"tovvSR9_QZQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","iter_num = 5\n","cv_num = 3\n","\n","lr_rand = RandomizedSearchCV(estimator = lr,\n","                       param_distributions = lr_params,\n","                         n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","svc_rand = RandomizedSearchCV(estimator = svc,\n","                       param_distributions = svc_params,\n","                          n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","svclin_rand = RandomizedSearchCV(estimator = svclin,\n","                       param_distributions = svclin_params,\n","                             n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","tree_rand = RandomizedSearchCV(estimator = tree,\n","                       param_distributions = tree_params,\n","                           n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","rftree_rand = RandomizedSearchCV(estimator = rftree,\n","                       param_distributions = rftree_params,\n","                             n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","ada_rand = RandomizedSearchCV(estimator = ada,\n","                       param_distributions = ada_params,\n","                          n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","gbc_rand = RandomizedSearchCV(estimator = gbc,\n","                       param_distributions = gbc_params,\n","                          n_iter = iter_num,\n","                       scoring = scorings[0],\n","                       cv = cv_num,\n","                       refit = True)\n","\n","rands = {'Logistic Regression' : lr_rand,\n","         'SVC' : svc_rand,\n","         'Linear SVC' : svclin_rand,\n","         'Decision Tree' : tree_rand,\n","         'Random Forest' : rftree_rand,\n","         'Ada Boost' : ada_rand,\n","         'Gradient Boost' : gbc_rand}"],"metadata":{"id":"vngCfJgMQcez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for key, rand in rands.items():\n","#    rand.fit(X_train, y_train)"],"metadata":{"id":"UA1oyk0zQfq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, rand in rands.items():\n","    rand.fit(X1_train, y1_train)"],"metadata":{"id":"ghAAXSQgQgzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, rand in rands.items():\n","    print(key)\n","    print(rand.best_params_)\n","    print('')"],"metadata":{"id":"flScLjZ8QiU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, rand in rands.items():\n","    print(key)\n","    print(rand.best_params_)\n","    print('')"],"metadata":{"id":"gfkMBkm9Qm6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report"],"metadata":{"id":"BOG0j7s7Qo06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, rand in rands.items():\n","    print('-----------------------------------------------------------')\n","    print(key)\n","    print('train score : {:.3f}'.format(rand.score(X_train, y_train)))\n","    print('test score  : {:.3f}'.format(rand.score(X_val, y_val)))\n","    print('')\n","    print('정확도      :', accuracy_score(y_val, rand.predict(X_val)))\n","    print('정밀도      :', precision_score(y_val, rand.predict(X_val)))\n","    print('재현율      :', recall_score(y_val, rand.predict(X_val)))\n","    print('F1 스코어   :', f1_score(y_val, rand.predict(X_val)))\n","    print('ROC_AUC     :', roc_auc_score(y_val, rand.predict(X_val)))\n","    print('-----------------------------------------------------------')\n","    print('')"],"metadata":{"id":"pIVXNlPZQqy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key, rand in rands.items():\n","    print('-----------------------------------------------------------')\n","    print(key)\n","    print('train score : {:.3f}'.format(rand.score(X1_train, y1_train)))\n","    print('test score  : {:.3f}'.format(rand.score(X1_val, y1_val)))\n","    print('')\n","    print('정확도      :', accuracy_score(y1_val, rand.predict(X1_val)))\n","    print('정밀도      :', precision_score(y1_val, rand.predict(X1_val)))\n","    print('재현율      :', recall_score(y1_val, rand.predict(X1_val)))\n","    print('F1 스코어   :', f1_score(y1_val, rand.predict(X1_val)))\n","    print('ROC_AUC     :', roc_auc_score(y1_val, rand.predict(X1_val)))\n","    print('-----------------------------------------------------------')\n","    print('')"],"metadata":{"id":"lAd82FpuQsm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub_df.info()"],"metadata":{"id":"j_AQyjEyQu1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = rands['Gradient Boost']"],"metadata":{"id":"qsqa1f4SQwXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df1 = test_df.drop(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpent'], axis=1)\n","test_df1.info()"],"metadata":{"id":"mJ3JHCsYQxtk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub = pd.DataFrame()\n","sub['PassengerId'] = sub_df['PassengerId']\n","sub['Transported'] = best_model.predict(test_df1)\n","sub['Transported'] = sub['Transported'].apply(lambda x : True if x == 1 else False)\n","\n","sub.info()"],"metadata":{"id":"9c2bvulAQzWZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub"],"metadata":{"id":"NmNg7vFUQ0th"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter Tuning"],"metadata":{"id":"M_UxhfZYQ2xX"}},{"cell_type":"code","source":["sub.to_csv('submission.csv', index=False)"],"metadata":{"id":"DPUjwjYrQ4FN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_grid = {\n","     'iterations': [200, 500, 800, 1000,1200],\n","     'learning_rate': [0.01, 0.1, 0.3],\n","     'border_count': [50, 100, 150,200],\n","     'depth': [4, 6, 8],\n","}\n","\n","catboost = CatBoostClassifier(verbose = False)\n","\n","randomize_search = RandomizedSearchCV(estimator=catboost, param_distributions=param_grid, cv=5)\n","\n","randomize_search.fit(X_train, y_train)\n","\n","best_params = randomize_search.best_params_\n","best_score = randomize_search.best_score_\n","best_catboost = CatBoostClassifier(**best_params)\n","best_catboost.fit(X_train, y_train)"],"metadata":{"id":"iyEaiL_OQ6GY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_params\n","best_score"],"metadata":{"id":"zefhmkzAQ8BJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = best_catboost.predict(X_val)\n","acc_cat = accuracy_score(y_val,y_pred)\n","print(\"Accuracy\",acc_cat)"],"metadata":{"id":"O-NDOJDyQ9dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_grid = {\n","     'iterations': [200, 500, 800, 1000,1200],\n","     'learning_rate': [0.01, 0.1, 0.3],\n","     'border_count': [50, 100, 150,200],\n","     'depth': [4, 6, 8],\n","}\n","\n","catboost = CatBoostClassifier(verbose = False)\n","\n","randomize_search = RandomizedSearchCV(estimator=catboost, param_distributions=param_grid, cv=5)\n","\n","randomize_search.fit(X1_train, y1_train)\n","\n","best_params = randomize_search.best_params_\n","best_score = randomize_search.best_score_\n","best_catboost = CatBoostClassifier(**best_params)\n","best_catboost.fit(X1_train, y1_train)\n","best_score"],"metadata":{"id":"iFA7K0kMRAeR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_params"],"metadata":{"id":"3KDeFY5-RFfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = best_catboost.predict(X_val)\n","acc_cat = accuracy_score(y_val,y_pred)\n","print(\"Accuracy\",acc_cat)"],"metadata":{"id":"gHTM6GNuRI2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# Define the parameter grid to search\n","param_grid = {\n","    'n_estimators': [300, 500,700,900,1100],\n","    'learning_rate': [0.01, 0.1, 0.3],\n","    'max_depth': [3, 5, 7],\n","    'num_leaves': [20, 30, 40],\n","    'reg_alpha': [0, 0.1, 0.5],\n","    'reg_lambda': [0, 0.1, 0.5]\n","}\n","\n","# Create the LGBMClassifier\n","lgbm = LGBMClassifier()\n","\n","# Perform random search with cross-validation\n","random_search = RandomizedSearchCV(estimator=lgbm, param_distributions=param_grid, n_iter=10, cv=5)\n","\n","# Fit the random search to the training data\n","random_search.fit(X_train, y_train)\n","\n","# Get the best hyperparameters and the best score\n","best_params = random_search.best_params_\n","best_score = random_search.best_score_\n","\n","# Create a new LGBMClassifier with the best hyperparameters\n","best_lgbm = LGBMClassifier(**best_params)\n","\n","# Train the model using the best hyperparameters\n","best_lgbm.fit(X_train, y_train)\n","best_params, best_score"],"metadata":{"id":"Xt_MGEMmRJj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = best_lgbm.predict(X_val)\n","acc_lgm = accuracy_score(y_val,y_pred)\n","#scores.append(['Only best lgm', acc_lgm])\n","print(\"Accuracy\",acc_lgm)"],"metadata":{"id":"ldr3Cfg4RM-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# Define the parameter grid to search\n","param_grid = {\n","    'n_estimators': [300, 500,700,900,1100],\n","    'learning_rate': [0.01, 0.1, 0.3],\n","    'max_depth': [3, 5, 7],\n","    'num_leaves': [20, 30, 40],\n","    'reg_alpha': [0, 0.1, 0.5],\n","    'reg_lambda': [0, 0.1, 0.5]\n","}\n","\n","# Create the LGBMClassifier\n","lgbm = LGBMClassifier()\n","\n","# Perform random search with cross-validation\n","random_search = RandomizedSearchCV(estimator=lgbm, param_distributions=param_grid, n_iter=10, cv=5)\n","\n","# Fit the random search to the training data\n","random_search.fit(X_train, y_train)\n","\n","# Get the best hyperparameters and the best score\n","best_params = random_search.best_params_\n","best_score = random_search.best_score_\n","\n","# Create a new LGBMClassifier with the best hyperparameters\n","best_lgbm = LGBMClassifier(**best_params)\n","\n","# Train the model using the best hyperparameters\n","best_lgbm.fit(X1_train, y1_train)\n","best_params, best_score"],"metadata":{"id":"xZLSQz0wRPk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = best_lgbm.predict(X1_val)\n","acc_lgm = accuracy_score(y1_val,y_pred)\n","#scores.append(['Only best lgm', acc_lgm])\n","print(\"Accuracy\",acc_lgm)"],"metadata":{"id":"geL6HIrPRR59"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Submission"],"metadata":{"id":"8KkQhdh1RUDp"}},{"cell_type":"code","source":["sub = pd.DataFrame()\n","sub['PassengerId'] = sub_df['PassengerId']\n","sub['Transported'] = best_lgbm.predict(test_df)\n","sub['Transported'] = sub['Transported'].apply(lambda x : True if x == 1 else False)\n","\n","sub.info()"],"metadata":{"id":"Xr1LtgMXRV4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub"],"metadata":{"id":"RdYgeUJyRX0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub.to_csv('submission.csv', index=False)"],"metadata":{"id":"t9wDfVeKRY42"},"execution_count":null,"outputs":[]}]}